{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/pacmann/loan-default-project/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the main directory\n",
    "# So, it's executed from main directory\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.env') as f:\n",
    "    os.environ.update(\n",
    "        line.strip().split('=') for line in f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/pacmann/loan-default-project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    input_train_path: Path\n",
    "    input_test_path: Path\n",
    "    output_train_path: Path\n",
    "    output_test_path: Path\n",
    "    encoded_train_path: Path\n",
    "    encoded_test_path: Path\n",
    "    encoder_model_path: Path\n",
    "    scaler_model_path: Path\n",
    "    model_path: Path\n",
    "    score_path: Path\n",
    "    mlflow_dataset_path: Path\n",
    "    mlflow_dataset_column: list\n",
    "    minio_endpoint_url: str\n",
    "    minio_access_key_id: str\n",
    "    minio_secret_access_key: str\n",
    "    mlflow_tracking_uri: str\n",
    "    mlflow_exp_name: str\n",
    "    mlflow_dataset_bucket: str\n",
    "    mlflow_run_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoanDefault.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from LoanDefault.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath = CONFIG_FILE_PATH,\n",
    "                 params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_train_eval_config(self) -> TrainEvaluationConfig:\n",
    "        \"\"\"read training evaluation config file and store as \n",
    "        config entity then apply the dataclasses\n",
    "        \n",
    "        Returns:\n",
    "            config: TrainEvaluationConfig type\n",
    "        \"\"\"\n",
    "        data_dump_config = self.config.dump_data\n",
    "        encoded_data_config = self.config.encoded_data\n",
    "        train_config = self.config.train_model\n",
    "        eval_config = self.config.train_evaluation\n",
    "\n",
    "        create_directories([eval_config.root_dir])\n",
    "\n",
    "        config = TrainEvaluationConfig(\n",
    "            root_dir=eval_config.root_dir,\n",
    "            input_train_path=Path(data_dump_config.input_train_path),\n",
    "            input_test_path=Path(data_dump_config.input_test_path),\n",
    "            output_train_path=Path(data_dump_config.output_train_path),\n",
    "            output_test_path=Path(data_dump_config.output_test_path),\n",
    "            encoded_train_path=Path(encoded_data_config.encoded_train_path),\n",
    "            encoded_test_path=Path(encoded_data_config.encoded_test_path),\n",
    "            encoder_model_path=Path(encoded_data_config.encoder_model_path),\n",
    "            scaler_model_path=Path(encoded_data_config.scaler_model_path),\n",
    "            model_path=Path(train_config.model_path),\n",
    "            score_path=Path(eval_config.score_path),\n",
    "            mlflow_dataset_path=Path(eval_config.mlflow_dataset_path),\n",
    "            mlflow_dataset_column=eval_config.mlflow_dataset_column,\n",
    "            minio_endpoint_url=os.environ['MLFLOW_S3_ENDPOINT_URL'],\n",
    "            minio_access_key_id=os.environ['AWS_ACCESS_KEY_ID'],\n",
    "            minio_secret_access_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n",
    "            mlflow_tracking_uri=os.environ[\"MLFLOW_TRACKING_URI\"],\n",
    "            mlflow_exp_name=eval_config.mlflow_exp_name,\n",
    "            mlflow_dataset_bucket=os.environ[\"PROJECT_BUCKET\"],\n",
    "            mlflow_run_name=eval_config.mlflow_run_name\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import joblib\n",
    "import mlflow\n",
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "from mlflow.data.dataset_source import DatasetSource\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from LoanDefault import logger\n",
    "\n",
    "class TrainEvaluation:\n",
    "    def __init__(self, config: TrainEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_prediction(self, model, X_input_enc, X_input) -> pd.DataFrame:\n",
    "        if isinstance(X_input_enc, tuple):\n",
    "            X_input_enc = X_input_enc[0]\n",
    "        y_predict = pd.Series(model.predict(X_input_enc), index=X_input.index)\n",
    "        return y_predict\n",
    "    \n",
    "    def get_report(self, y_output, y_predict) -> dict:\n",
    "        metrics = classification_report(y_output, y_predict, output_dict=True)\n",
    "        \n",
    "        logger.info(f\"Save report as json.\")\n",
    "        save_json(path=self.config.score_path, data=metrics)\n",
    "        \n",
    "        logger.info(f\"Show the training report.\")\n",
    "        print(f\"\\n{classification_report(y_output, y_predict)}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def get_mlflow_metrics(self, metrics) -> dict:\n",
    "        mlflow_metrics = {}\n",
    "\n",
    "        max_iterations = min(len(metrics), 2)\n",
    "\n",
    "        for rating in range(max_iterations):\n",
    "            data_metric = metrics.get(str(rating))\n",
    "            if data_metric:\n",
    "                for name, value in data_metric.items():\n",
    "                    mlflow_metrics[name + \"_\" + str(rating)] = value\n",
    "            \n",
    "        return mlflow_metrics\n",
    "    \n",
    "    def get_dataset(self, X_input, y_output, y_predict) -> pd.DataFrame:\n",
    "        logger.info(f\"Creating dataset for MLflow logging.\")\n",
    "\n",
    "        # Convert y_output and y_predict to DataFrame with appropriate names\n",
    "        y_output_df = pd.DataFrame(y_output, index=X_input.index, columns=['Default'])\n",
    "        y_predict_df = pd.DataFrame(y_predict, index=X_input.index, columns=['predictions'])\n",
    "\n",
    "        # Combine X_input, y_output, and y_predict into a single DataFrame\n",
    "        train_eval_result = pd.concat([X_input, y_output_df, y_predict_df], axis=1)\n",
    "\n",
    "        # Log the number of columns and their names before renaming\n",
    "        logger.info(f\"Number of columns in X_input: {X_input.shape[1]}\")\n",
    "        logger.info(f\"Number of rows in y_output: {y_output.shape[0]}\")\n",
    "        logger.info(f\"Number of rows in y_predict: {y_predict.shape[0]}\")\n",
    "        logger.info(f\"Number of columns in combined dataset: {train_eval_result.shape[1]}\")\n",
    "        logger.info(f\"Column names in combined dataset: {train_eval_result.columns.tolist()}\")\n",
    "\n",
    "        # Log the expected column names\n",
    "        logger.info(f\"Expected column names: {self.config.mlflow_dataset_column}\")\n",
    "\n",
    "        # Check if the number of columns matches the expected number\n",
    "        if len(self.config.mlflow_dataset_column) != train_eval_result.shape[1]:\n",
    "            logger.error(f\"Length mismatch: Expected axis has {train_eval_result.shape[1]} elements, new values have {len(self.config.mlflow_dataset_column)} elements\")\n",
    "            raise ValueError(f\"Length mismatch: Expected axis has {train_eval_result.shape[1]} elements, new values have {len(self.config.mlflow_dataset_column)} elements\")\n",
    "\n",
    "        # Assign new column names\n",
    "        train_eval_result.columns = self.config.mlflow_dataset_column\n",
    "        logger.info(f\"Dataset columns after renaming: {train_eval_result.columns.tolist()}\")\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        train_eval_result.to_csv(self.config.mlflow_dataset_path, index=False)\n",
    "\n",
    "        return train_eval_result\n",
    "        \n",
    "    def get_mlflow_dataset(self, mlflow_dataset, run_name) -> PandasDataset:\n",
    "        mlflow_dataset = mlflow.data.from_pandas(\n",
    "            mlflow_dataset,\n",
    "            source=DatasetSource.load(f\"s3://{self.config.mlflow_dataset_bucket}/{run_name}.csv\"),\n",
    "            name=f\"{run_name}\",\n",
    "            targets=self.config.mlflow_dataset_column[-2],  # 'Default'\n",
    "            predictions=self.config.mlflow_dataset_column[-1]  # 'predictions'\n",
    "        )\n",
    "        \n",
    "        return mlflow_dataset\n",
    "\n",
    "    \n",
    "    def s3_upload_mlflow_dataset(self, run_name) -> None:\n",
    "        s3 = boto3.client('s3',\n",
    "                              endpoint_url=self.config.minio_endpoint_url,\n",
    "                              aws_access_key_id=self.config.minio_access_key_id,\n",
    "                              aws_secret_access_key=self.config.minio_secret_access_key)\n",
    "        \n",
    "        try:\n",
    "            s3.upload_file(\n",
    "                self.config.mlflow_dataset_path, \n",
    "                self.config.mlflow_dataset_bucket, \n",
    "                f'{run_name}.csv'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            raise e\n",
    "    \n",
    "    def mlflow_log_train(self) -> None:\n",
    "        try:\n",
    "            logger.info(f\"Load encoded data train from {self.config.encoded_train_path}.\")\n",
    "            X_train_enc = joblib.load(self.config.encoded_train_path)\n",
    "\n",
    "            logger.info(f\"Load data train from {self.config.input_train_path}.\")\n",
    "            X_train = joblib.load(self.config.input_train_path)\n",
    "            X_test = joblib.load(self.config.input_test_path)\n",
    "\n",
    "            logger.info(f\"Load data train output from {self.config.output_train_path}.\")\n",
    "            y_train = joblib.load(self.config.output_train_path)\n",
    "\n",
    "            logger.info(f\"Load the model.\")\n",
    "            model = joblib.load(self.config.model_path)\n",
    "\n",
    "            logger.info(f\"Type of X_train_enc: {type(X_train_enc)}\")\n",
    "            logger.info(f\"Example of X_train_enc: {X_train_enc[:1]}\")\n",
    "            logger.info(f\"Type of X_train: {type(X_train)}\")\n",
    "            logger.info(f\"Example of X_train: {X_train[:1]}\")\n",
    "\n",
    "            if isinstance(X_train_enc, tuple):\n",
    "                X_train_enc = X_train_enc[0]\n",
    "\n",
    "            if hasattr(X_train_enc, 'shape') and hasattr(X_train, 'shape'):\n",
    "                logger.info(f\"Checking shapes of X_train_enc: {X_train_enc.shape} and X_train: {X_train.shape}\")\n",
    "            else:\n",
    "                logger.error(\"X_train_enc or X_train does not have attribute 'shape'. Please check the data type.\")\n",
    "                raise ValueError(\"X_train_enc or X_train does not have attribute 'shape'. Please check the data type.\")\n",
    "\n",
    "            logger.info(f\"Predicting the data train.\")\n",
    "            y_train_pred = self.get_prediction(model, X_train_enc, X_train)\n",
    "\n",
    "            logger.info(f\"Generate classification report.\")\n",
    "            train_report = self.get_report(y_train, y_train_pred)\n",
    "\n",
    "            logger.info(f\"Set tracking URI.\")\n",
    "            mlflow.set_tracking_uri(self.config.mlflow_tracking_uri)\n",
    "\n",
    "            logger.info(f\"Set experiment name.\")\n",
    "            mlflow.set_experiment(self.config.mlflow_exp_name)\n",
    "\n",
    "            logger.info(f\"Set run name.\")\n",
    "            flag = ''.join(random.choices(\n",
    "                string.ascii_uppercase + string.ascii_lowercase + string.digits, \n",
    "                k=5))\n",
    "            run_name = f\"{self.config.mlflow_run_name}-{flag}\"\n",
    "\n",
    "            logger.info(f\"Construct report for MLflow.\")\n",
    "            mlflow_metrics = self.get_mlflow_metrics(train_report)\n",
    "\n",
    "            logger.info(f\"Construct MLflow dataset file in {self.config.mlflow_dataset_path}.\")\n",
    "            \n",
    "            logger.info(f\"Number of columns in X_train: {X_train.shape[1]}\")\n",
    "            logger.info(f\"Number of rows in y_train: {y_train.shape[0]}\")\n",
    "            logger.info(f\"Number of rows in y_train_pred: {y_train_pred.shape[0]}\")\n",
    "            \n",
    "            mlflow_train_dataset = self.get_dataset(X_train, y_train, y_train_pred)\n",
    "\n",
    "            logger.info(f\"Construct MLflow input example.\")\n",
    "            sample = 10\n",
    "            input_example = {\"loanContents\": X_train.head(sample).to_dict(orient='records')}\n",
    "\n",
    "            logger.info(f\"Experiment tracking to evaluate model with MLflow.\")\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                logger.info(f\"Upload {self.config.mlflow_dataset_path} file to MinIO.\")\n",
    "                self.s3_upload_mlflow_dataset(run_name)\n",
    "\n",
    "                logger.info(f\"Set MLflow dataset.\")\n",
    "                dataset = self.get_mlflow_dataset(mlflow_train_dataset, run_name)\n",
    "\n",
    "                logger.info(f\"Logging to MLflow as an experiment.\")\n",
    "                model_params = model.get_params()\n",
    "                mlflow.log_params(model_params)\n",
    "                mlflow.log_metrics(mlflow_metrics)\n",
    "                mlflow.log_input(dataset, context=\"training\")\n",
    "                mlflow.log_artifact(self.config.encoder_model_path, \"encoder\")\n",
    "                mlflow.log_artifact(self.config.scaler_model_path, \"scaler\")\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"models\",\n",
    "                    serialization_format=mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,\n",
    "                    registered_model_name=\"logistic_regression\",\n",
    "                    input_example=input_example\n",
    "                )\n",
    "                mlflow.set_tags(\n",
    "                    {\n",
    "                        \"dataset\": \"loan default training dataset and prediction result\",\n",
    "                        \"model\": \"logistic_regression\"\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-13 10:05:36,079: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-07-13 10:05:36,094: INFO: common: yaml file: metrics/params.yaml loaded successfully]\n",
      "[2024-07-13 10:05:36,096: INFO: common: created directory at: artifacts]\n",
      "[2024-07-13 10:05:36,105: INFO: common: created directory at: artifacts/predict]\n",
      "[2024-07-13 10:05:36,107: INFO: 1594587430: Load encoded data train from artifacts/preprocessing/X_train_encoded.pkl.]\n",
      "[2024-07-13 10:05:36,319: INFO: 1594587430: Load data train from artifacts/data/X_train.pkl.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-13 10:05:40,419: INFO: 1594587430: Load data train output from artifacts/data/y_train.pkl.]\n",
      "[2024-07-13 10:05:40,451: INFO: 1594587430: Load the model.]\n",
      "[2024-07-13 10:05:40,666: INFO: 1594587430: Type of X_train_enc: <class 'tuple'>]\n",
      "[2024-07-13 10:05:40,668: INFO: 1594587430: Example of X_train_enc: (array([[-0.49614949, -1.27925561, -0.34566167, ...,  1.        ,\n",
      "         1.        ,  0.        ],\n",
      "       [-1.6988325 ,  1.59211763, -0.70186312, ...,  0.        ,\n",
      "         0.        ,  1.        ],\n",
      "       [-0.29570232, -1.47514003, -0.63525393, ...,  0.        ,\n",
      "         1.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 1.64195363, -1.60723381, -0.90683951, ...,  0.        ,\n",
      "         0.        ,  1.        ],\n",
      "       [-1.16430672, -1.42409214, -1.07679267, ...,  0.        ,\n",
      "         1.        ,  0.        ],\n",
      "       [-1.56520105, -0.12235815, -0.78158481, ...,  0.        ,\n",
      "         0.        ,  1.        ]]),)]\n",
      "[2024-07-13 10:05:40,670: INFO: 1594587430: Type of X_train: <class 'pandas.core.frame.DataFrame'>]\n",
      "[2024-07-13 10:05:40,705: INFO: 1594587430: Example of X_train:         Age  Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  \\\n",
      "186723   36   32710      103395          661              51               2   \n",
      "\n",
      "        InterestRate  LoanTerm  DTIRatio Education EmploymentType  \\\n",
      "186723         22.46        60      0.25       PhD  Self-employed   \n",
      "\n",
      "       MaritalStatus HasMortgage HasDependents LoanPurpose HasCoSigner  \n",
      "186723        Single         Yes           Yes       Other          No  ]\n",
      "[2024-07-13 10:05:40,707: INFO: 1594587430: Checking shapes of X_train_enc: (51069, 31) and X_train: (51069, 16)]\n",
      "[2024-07-13 10:05:40,711: INFO: 1594587430: Predicting the data train.]\n",
      "[2024-07-13 10:05:40,731: INFO: 1594587430: Generate classification report.]\n",
      "[2024-07-13 10:05:40,903: INFO: 1594587430: Save report as json.]\n",
      "[2024-07-13 10:05:40,906: INFO: common: json file saved at: metrics/scores.json]\n",
      "[2024-07-13 10:05:40,907: INFO: 1594587430: Show the training report.]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     45232\n",
      "           1       0.61      0.03      0.05      5837\n",
      "\n",
      "    accuracy                           0.89     51069\n",
      "   macro avg       0.75      0.51      0.49     51069\n",
      "weighted avg       0.86      0.89      0.84     51069\n",
      "\n",
      "[2024-07-13 10:05:41,019: INFO: 1594587430: Set tracking URI.]\n",
      "[2024-07-13 10:05:41,020: INFO: 1594587430: Set experiment name.]\n",
      "[2024-07-13 10:07:41,164: WARNING: connectionpool: Retrying (Retry(total=4, connect=4, read=5, redirect=5, status=5)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7ed088c170>, 'Connection to 18.183.36.127 timed out. (connect timeout=120)')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=Loan+Default+Classification]\n",
      "[2024-07-13 10:09:46,134: WARNING: connectionpool: Retrying (Retry(total=3, connect=3, read=5, redirect=5, status=5)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f7ecbf75a90>, 'Connection to 18.183.36.127 timed out. (connect timeout=120)')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=Loan+Default+Classification]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_train_eval_config()\n",
    "    evaluation = TrainEvaluation(config=eval_config)\n",
    "    evaluation.mlflow_log_train()\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Number of columns in DataFrame: {X_train.shape[1]}\")\n",
    "logger.info(f\"Number of new column names: {len(new_column_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(mlflow.last_active_run().info.run_id)\n",
    "dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "print(f\"Dataset name: {dataset_info.name}\")\n",
    "print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "print(f\"Dataset schema: {dataset_info.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_train_eval_config()\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                    endpoint_url=eval_config.minio_endpoint_url,\n",
    "                    aws_access_key_id=eval_config.minio_access_key_id,\n",
    "                    aws_secret_access_key=eval_config.minio_secret_access_key)\n",
    "\n",
    "    obj = s3.get_object(Bucket=eval_config.mlflow_dataset_bucket, Key=f\"{dataset_info.name}.csv\") \n",
    "    df = pd.read_csv(obj['Body'])\n",
    "except Exception as e:\n",
    "    logger.error(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lazada-id-reviews-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
